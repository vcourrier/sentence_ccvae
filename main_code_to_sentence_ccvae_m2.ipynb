{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import math\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.utils import make_grid, save_image\n",
    "import torch.distributions as dist\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Arthur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Arthur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Arthur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Fun, entertaining movie about WWII German spy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Give me a break. How can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>This movie is a bad movie. But after watching ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>This is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Smashing film about film-making. Shows the int...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     One of the other reviewers has mentioned that ...  positive\n",
       "1     A wonderful little production. <br /><br />The...  positive\n",
       "2     I thought this was a wonderful way to spend ti...  positive\n",
       "3     Basically there's a family where a little boy ...  negative\n",
       "4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Fun, entertaining movie about WWII German spy ...  positive\n",
       "9996  Give me a break. How can anyone say that this ...  negative\n",
       "9997  This movie is a bad movie. But after watching ...  negative\n",
       "9998  This is a movie that was probably made to ente...  negative\n",
       "9999  Smashing film about film-making. Shows the int...  positive\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "  \n",
    "\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "#stemmer = PorterStemmer()\n",
    "\n",
    "df_tok = df[:10000].copy() \n",
    "\n",
    "df_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, remove stopwords, and stem\n",
    "df_tok['review'] = df_tok['review'].apply(lambda x: word_tokenize(x.lower()))\n",
    "print(\"Tokenized\")\n",
    "#df_tok['review'] = df_tok['review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "#print(\"Removed stopwords\")\n",
    "#df_tok['review'] = df_tok['review'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "#print(\"Stemmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit vocabulary size\n",
    "vocab_size = 10000\n",
    "all_words = [word for review in df_tok['review'] for word in review]\n",
    "word_counts = Counter(all_words)\n",
    "most_common_words = set([word for word, count in word_counts.most_common(vocab_size)])\n",
    "\n",
    "df_tok['review'] = df_tok['review'].apply(lambda x: [word if word in most_common_words else '<UNK>' for word in x])\n",
    "\n",
    "# Encode reviews\n",
    "word2value = {word: idx for idx, word in enumerate(most_common_words, start=1)}\n",
    "word2value['<UNK>'] = 0\n",
    "\n",
    "df_enc = df_tok.copy()\n",
    "df_enc['review'] = df_enc['review'].apply(lambda x: [word2value[word] for word in x])\n",
    "\n",
    "# Convert to tensors and pad\n",
    "review_tensors = [torch.tensor(encoded_review) for encoded_review in df_enc['review']]\n",
    "padded = pad_sequence(review_tensors, batch_first=True, padding_value=0).narrow(1, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review  sentiment\n",
      "0     [7759, 2175, 6046, 6132, 1739, 7074, 4869, 553...          1\n",
      "1     [7288, 8050, 9881, 9776, 8880, 9549, 5673, 527...          1\n",
      "2     [8994, 2373, 5143, 1683, 7288, 8050, 4542, 464...          1\n",
      "3     [573, 4082, 8812, 7288, 3695, 551, 7288, 9881,...          0\n",
      "4     [0, 4777, 8812, 7021, 9773, 3709, 6046, 9746, ...          1\n",
      "...                                                 ...        ...\n",
      "9995  [172, 5131, 6534, 698, 5250, 9507, 83, 2286, 1...          1\n",
      "9996  [343, 2651, 7288, 2939, 8880, 2386, 382, 8527,...          0\n",
      "9997  [5143, 698, 5816, 7288, 6915, 698, 8880, 84, 3...          0\n",
      "9998  [5143, 5816, 7288, 698, 5538, 1683, 713, 6266,...          0\n",
      "9999  [4518, 1376, 5250, 5694, 8880, 4385, 6046, 868...          1\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "Training set shape: (8500, 2)\n",
      "Testing set shape: (1500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store values for the DataFrame\n",
    "reviews = []\n",
    "sentiment_values = []\n",
    "\n",
    "# Iterate over each row of the tensor\n",
    "for i in range(padded.size(0)):\n",
    "    # Extract the row from the tensor\n",
    "    row = padded[i]\n",
    "    \n",
    "    # Convert the tensor row to a list and append it to the 'reviews' list\n",
    "    reviews.append(row.tolist())\n",
    "    # Extract the corresponding value of 'sentiment' column from the other DataFrame\n",
    "    sentiment_value = df_tok.iloc[i]['sentiment']\n",
    "    # Append the value to the 'sentiment_values' list\n",
    "    if sentiment_value == \"positive\" :\n",
    "        sentiment_values.append(1)\n",
    "    else :\n",
    "        sentiment_values.append(0)\n",
    "\n",
    "# Final dataframe\n",
    "final_df = pd.DataFrame({'review': reviews, 'sentiment': sentiment_values})\n",
    "\n",
    "print(final_df)\n",
    "\n",
    "\n",
    "####### Train-test split ########\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(final_df, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Testing set shape:\", test_df.shape)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract features and labels for a single row\n",
    "        features = torch.tensor(self.dataframe.iloc[idx]['review'], dtype=torch.float32) \n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['sentiment'], dtype=torch.long)\n",
    "        index = torch.tensor(self.dataframe.iloc[idx].name, dtype=torch.long)  \n",
    "        return index, features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and number of epochs\n",
    "batch_size = 200\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "data_train = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocs du modÃ¨le\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, z_dim, hidden_dim, bidirectional=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_factor = 2 if bidirectional else 1\n",
    "\n",
    "        self.encoder = nn.LSTM(input_size, hidden_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.locs = nn.Linear(hidden_dim*self.hidden_factor, z_dim)\n",
    "        self.scales = nn.Linear(hidden_dim*self.hidden_factor, z_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # x should be of shape [batch_size, seq_len, input_size]\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0).unsqueeze(0)  # shape [1, 1, input_size]\n",
    "        elif x.dim() == 2:\n",
    "            x = x.unsqueeze(2)  # shape [batch_size, 1, input_size]\n",
    "        \n",
    "        output, (hidden, c_n) = self.encoder(x)\n",
    "        #print(\"pre hidden\", h_n.shape)\n",
    "        #hidden = h_n[-1]\n",
    "        hidden = hidden.view(batch_size, self.hidden_dim*self.hidden_factor)\n",
    "\n",
    "        locs = self.locs(hidden)\n",
    "        scales = torch.clamp(F.softplus(self.scales(hidden)), min=1e-3)\n",
    "        return locs, scales\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, z_dim, hidden_dim, vocab_size, bidirectional=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_size = input_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_factor = 2 if bidirectional else 1\n",
    "\n",
    "        # Linear layer to transform z_dim to hidden_dim\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim * self.hidden_factor)\n",
    "\n",
    "        # LSTM to generate sequences\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, bidirectional=bidirectional, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim * self.hidden_factor, self.vocab_size+1)\n",
    "\n",
    "    def forward(self, z, xs):\n",
    "        batch_size = z.size(0)\n",
    "        seq_len = xs.size(1)\n",
    "\n",
    "        # Transform latent vector to initial hidden state\n",
    "        hidden = self.linear(z).view(self.hidden_factor, batch_size, self.hidden_dim)\n",
    "\n",
    "        if xs.is_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        c_0 = torch.zeros(self.hidden_factor, batch_size, self.hidden_dim)\n",
    "        if xs.is_cuda:\n",
    "            c_0 = c_0.cuda()\n",
    "\n",
    "        decoder_hidden = (hidden, c_0)\n",
    "\n",
    "        # Forward pass through LSTM\n",
    "        outputs, _ = self.lstm(xs, decoder_hidden)\n",
    "\n",
    "        outputs = self.output(outputs)\n",
    "        # Apply log softmax to get log probabilities over the vocabulary\n",
    "        logp = nn.functional.log_softmax(outputs, dim=-1)\n",
    "        return logp\n",
    "\n",
    "class Diagonal(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Diagonal, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.weight = nn.Parameter(torch.ones(self.dim))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.weight + self.bias\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.diag = Diagonal(self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.diag(x)\n",
    "\n",
    "class CondPrior(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(CondPrior, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.diag_loc_true = nn.Parameter(torch.zeros(self.dim))\n",
    "        self.diag_loc_false = nn.Parameter(torch.zeros(self.dim))\n",
    "        self.diag_scale_true = nn.Parameter(torch.ones(self.dim))\n",
    "        self.diag_scale_false = nn.Parameter(torch.ones(self.dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) \n",
    "        loc = x * self.diag_loc_true + (1 - x) * self.diag_loc_false\n",
    "        scale = x * self.diag_scale_true + (1 - x) * self.diag_scale_false\n",
    "        return loc, torch.clamp(F.softplus(scale), min=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCVAE model\n",
    "\n",
    "def compute_kl(locs_q, scale_q, locs_p=None, scale_p=None):\n",
    "    \"\"\"\n",
    "    Computes the KL(q||p)\n",
    "    \"\"\"\n",
    "    if locs_p is None:\n",
    "        locs_p = torch.zeros_like(locs_q)\n",
    "    if scale_p is None:\n",
    "        scale_p = torch.ones_like(scale_q)\n",
    "\n",
    "    dist_q = dist.Normal(locs_q, scale_q)\n",
    "    dist_p = dist.Normal(locs_p, scale_p)\n",
    "    return dist.kl.kl_divergence(dist_q, dist_p).sum(dim=-1)\n",
    "\n",
    "def img_log_likelihood(recon, xs):\n",
    "        if xs.dim() == 1:\n",
    "            xs = xs.unsqueeze(0).unsqueeze(0)  # shape [1, 1, input_size]\n",
    "            recon = recon.unsqueeze(0).unsqueeze(0)\n",
    "        elif xs.dim() == 2:\n",
    "            xs = xs.unsqueeze(1)  # shape [batch_size, 1, input_size]\n",
    "            recon = recon.unsqueeze(1)\n",
    "        laplace_dist = dist.Laplace(recon, torch.ones_like(recon))\n",
    "        log_prob = laplace_dist.log_prob(xs)\n",
    "        return log_prob.sum(dim=(0, 1, 2))\n",
    "\n",
    "def sentence_log_likelihood(recon, xs):\n",
    "    vocab_size = recon.shape[-1] \n",
    "    \n",
    "    target = xs.squeeze(-1)  # Shape: (batch_size, seq_len)\n",
    "    target = target.long()\n",
    "\n",
    "    # Reshape output and target for CrossEntropyLoss\n",
    "    recon = recon.view(-1, vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
    "    target = target.view(-1)  # Shape: (batch_size * seq_len)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(recon, target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "class CCVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    CCVAE\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_dim, vocab_size, z_dim, num_classes, use_cuda, prior_fn):\n",
    "        super(CCVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.z_classify = num_classes\n",
    "        self.z_style = z_dim - num_classes\n",
    "        self.use_cuda = use_cuda\n",
    "        self.num_classes = num_classes\n",
    "        self.ones = torch.ones(1, self.z_style)\n",
    "        self.zeros = torch.zeros(1, self.z_style)\n",
    "        self.y_prior_params = prior_fn\n",
    "\n",
    "        self.classifier = Classifier(self.num_classes)\n",
    "\n",
    "        self.encoder = Encoder(self.input_size, self.z_dim, self.hidden_dim)\n",
    "        self.decoder = Decoder(self.input_size, self.z_dim, self.hidden_dim, self.vocab_size)\n",
    "\n",
    "        self.cond_prior = CondPrior(self.num_classes)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.ones = self.ones.cuda()\n",
    "            self.zeros = self.zeros.cuda()\n",
    "            self.y_prior_params = self.y_prior_params.cuda()\n",
    "            self.cuda()\n",
    "\n",
    "    def sup(self, x, y):\n",
    "        y = y.float()\n",
    "        bs = x.shape[0]\n",
    "        #inference\n",
    "        post_params = self.encoder(x)\n",
    "        \n",
    "        z = dist.Normal(*post_params).rsample()\n",
    "        zc, zs = z.split([self.z_classify, self.z_style], 1)\n",
    "        qyzc = dist.Bernoulli(logits=self.classifier(zc))\n",
    "        log_qyzc = qyzc.log_prob(y.view(-1, 1)).sum(dim=-1)\n",
    "\n",
    "        # compute kl\n",
    "        locs_p_zc, scales_p_zc = self.cond_prior(y)\n",
    "        prior_params = (torch.cat([locs_p_zc, self.zeros.expand(bs, -1)], dim=1), \n",
    "                        torch.cat([scales_p_zc, self.ones.expand(bs, -1)], dim=1))\n",
    "        kl = compute_kl(*post_params, *prior_params)\n",
    "\n",
    "        #compute log probs for x and y\n",
    "\n",
    "        log_py = dist.Bernoulli(self.y_prior_params.expand(bs, -1)).log_prob(y.view(-1, 1)).sum(dim=-1)\n",
    "\n",
    "        recon = self.decoder(z, x)\n",
    "\n",
    "        log_qyx = self.classifier_loss(x, y)\n",
    "        #recon = recon.transpose(0, 1)\n",
    "        #recon = recon.reshape(bs, -1, 1)  # Transpose back to [batch_size, seq_len, hidden_dim]\n",
    "        log_pxz = sentence_log_likelihood(recon, x)\n",
    "\n",
    "\n",
    "        # we only want gradients wrt to params of qyz, so stop them propogating to qzx\n",
    "        log_qyzc_ = dist.Bernoulli(logits=self.classifier(zc.detach())).log_prob(y.view(-1, 1)).sum(dim=-1)\n",
    "        #print(\"log_qyzc_\", log_qyzc_, \"\\nlog_qyx\", log_qyx)\n",
    "        w = torch.exp(log_qyzc_ - log_qyx)+ 1e-8\n",
    "        elbo = (w * (-log_pxz - kl - log_qyzc) + log_py + log_qyx).mean()\n",
    "        return -elbo\n",
    "\n",
    "    def classifier_loss(self, x, y, k=100):\n",
    "        \"\"\"\n",
    "        Computes the classifier loss.\n",
    "        \"\"\"\n",
    "        zc, _ = dist.Normal(*self.encoder(x)).rsample(torch.tensor([k])).split([self.z_classify, self.z_style], -1)\n",
    "        logits = self.classifier(zc.view(-1, self.z_classify))\n",
    "        d = dist.Bernoulli(logits=logits)\n",
    "        y = y.unsqueeze(0).unsqueeze(-1)\n",
    "        y = y.expand(k, -1, -1).contiguous().view(-1, self.num_classes)\n",
    "        lqy_z = d.log_prob(y).view(k, x.shape[0], self.num_classes).sum(dim=-1)\n",
    "        lqy_x = torch.logsumexp(lqy_z, dim=0) - np.log(k)\n",
    "        return lqy_x\n",
    "\n",
    "    #def reconstruct_img(self, x):\n",
    "    #    return self.decoder(dist.Normal(*self.encoder(x)).rsample())\n",
    "\n",
    "    def classifier_acc(self, x, y=None, k=1):\n",
    "        zc, _ = dist.Normal(*self.encoder(x)).rsample(torch.tensor([k])).split([self.z_classify, self.z_style], -1)\n",
    "        logits = self.classifier(zc.view(-1, self.z_classify)).view(-1, self.num_classes)\n",
    "        y = y.unsqueeze(0).unsqueeze(-1)\n",
    "        y = y.expand(k, -1, -1).contiguous().view(-1, self.num_classes)\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        acc = (preds.eq(y)).float().mean()\n",
    "        return acc\n",
    "    \n",
    "    def accuracy(self, data_loader, *args, **kwargs):\n",
    "        acc = 0.0\n",
    "        for (_, x, y) in data_loader:\n",
    "            if self.use_cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            batch_acc = self.classifier_acc(x, y)\n",
    "            acc += batch_acc\n",
    "        return acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 \n",
    "seq_len = 100\n",
    "hidden_dim = 256\n",
    "z_dim = 28\n",
    "num_classes = 1\n",
    "use_cuda = False\n",
    "prior_fn = torch.tensor([[0.5]])\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batch = int(len(train_dataset)/batch_size)\n",
    "num_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "  Batch: 0\n",
      "Batch 0 Loss: 20.146\n",
      "  Batch: 1\n",
      "Batch 1 Loss: 17.667\n",
      "  Batch: 2\n",
      "Batch 2 Loss: 15.381\n",
      "  Batch: 3\n",
      "Batch 3 Loss: 13.668\n",
      "  Batch: 4\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Training\n",
    "cc_vae = CCVAE(input_size, hidden_dim, vocab_size, z_dim, num_classes, use_cuda, prior_fn)\n",
    "\n",
    "cc_vae.apply(init_weights)\n",
    "\n",
    "optim = torch.optim.Adam(params=cc_vae.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    cc_vae.train()\n",
    "    \n",
    "    epoch_losses_sup = 0.0\n",
    "    for batch_idx, (_, xs, ys) in enumerate(train_loader):\n",
    "        print(\"  Batch:\", batch_idx)\n",
    "        xs = xs.view(xs.shape[0], seq_len, input_size)\n",
    "        loss = cc_vae.sup(xs, ys)\n",
    "        \n",
    "        optim.zero_grad() \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_losses_sup += loss.detach().item()\n",
    "        print(f\"Batch {batch_idx} Loss: {loss.detach().item():.3f}\")\n",
    "        gc.collect()\n",
    "    \n",
    "    avg_loss = epoch_losses_sup / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1:03d}] Sup Loss: {avg_loss:.3f}\")\n",
    "\n",
    "#cc_vae.eval() \n",
    "#test_acc = cc_vae.accuracy(test_loader)\n",
    "\n",
    "#print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5019)\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "cc_vae.eval() \n",
    "\n",
    "test_acc = cc_vae.accuracy(test_loader)\n",
    "\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervention\n",
    "\n",
    "def intervention(model, x, y):\n",
    "    post_params = model.encoder(x)\n",
    "    z = dist.Normal(*post_params).rsample()\n",
    "    zc, zs = z.split([model.z_classify, model.z_style], 1)\n",
    "    locs_p_zc, scales_p_zc = model.cond_prior(1 - y)\n",
    "    zc_new = dist.Normal(locs_p_zc, scales_p_zc).rsample()\n",
    "    z_new = torch.cat((zc_new,zs),dim=1)\n",
    "    recons = model.decoder(z_new,x)\n",
    "    return recons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "value2word = {v: k for k, v in word2value.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_recons(recons):\n",
    "    recons = recons.round()\n",
    "    r = torch.zeros(recons.shape[1])\n",
    "    for i in range(recons.shape[1]):\n",
    "        r[i] = torch.argmax(recons[0][i]) \n",
    "    decoded_review = [value2word.get(idx.item(), '<UNK>') for idx in r]\n",
    "    decoded_text = '.'.join(decoded_review)\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True review ['this', 'is', 'a', 'pretty', 'pointless', 'remake', '.', 'starting', 'with', 'the', 'opening', 'title', 'shots', 'of', 'the', 'original', 'was', 'a', 'real', 'mistake', 'as', 'it', 'reminds', 'the', 'viewer', 'of', 'what', 'a', 'great', 'little', 'period', 'piece', '<UNK>', 'that', 'was', '.', 'the', 'new', 'version', 'that', 'follows', 'is', 'an', 'exercise', 'in', '<UNK>', '<', 'br', '/', '>', '<', 'br', '/', '>', 'brian', '<UNK>', 'plays', 'a', '<UNK>', 'boy', \"'\", 'photographer', 'who', 'returns', 'to', 'a', '<UNK>', 'desert', 'town', 'populated', 'by', 'a', '<UNK>', 'of', '<UNK>', 'clichÃ©d', 'stock', 'characters', ':', 'the', '<UNK>', 'sucking', '<UNK>', '<UNK>', ',', 'the', '<UNK>', 'old', '<UNK>', '<UNK>', ',', 'the', 'crippled', 'vet', 'and', 'his', 'asian', 'wife', ',', 'etc', '...', '<', 'br', '/', '>', '<', 'br', '/', '>', '<UNK>', \"'s\", 'character', 'witnesses', 'the', 'crashing', 'of', '<UNK>', \"'\", 'into', 'a', '<UNK>', 'and', 'shortly', 'after', 'strange', 'things', 'start', 'to', 'happen', 'as', 'pieces', 'of', 'weird', 'blue', 'rock', 'are', 'scattered', 'around', '.', 'the', '<UNK>', 'starts', 'to', 'rise', ',', 'all', 'the', 'water', 'in', 'the', 'area', 'vanishes', ',', 'people', 'start', 'to', 'act', '<UNK>', ',', 'things', 'explode', '.', '<UNK>', \"'s\", 'character', 'gets', 'in', 'and', 'out', 'of', 'his', 'car', 'more', 'often', 'than', 'is', '<UNK>', 'possible', 'in', 'one', 'movie', '.', 'the', 'film', 'develops', 'no', 'sense', 'of', 'place', ',', 'no', 'character', 'development', ',', 'no', 'humour', ',', 'no', 'tension', '.', 'everything', 'that', 'made', 'the', 'jack', 'arnold', \"'s\", 'original', 'a', 'creepy', 'little', '<UNK>', 'paranoia', 'classic', 'has', 'been', 'abandoned', '.', 'it', 'just', 'runs', 'through', 'its', 'minimal', '<UNK>', 'and', 'then', 'just', '<UNK>', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'special', 'effects', 'are', \"n't\", 'very', 'special', '-', 'the', 'interior', 'of', 'the', 'ship', 'looks', 'like', 'bits', 'of', '<UNK>', 'film', 'wrapped', 'round', 'some', '<UNK>', 'which', 'were', 'then', '<UNK>', 'in', 'front', 'of', 'the', 'camera', 'to', 'frame', 'some', 'of', 'the', 'most', 'uninspired', 'and', 'clumsy', '<UNK>', 'ever', 'put', 'onto', 'the', 'screen', '.', 'the', 'script', 'is', 'repetitive', '-', 'everyone', 'says', 'everything', 'at', 'least', 'twice', ',', '<UNK>', 'gets', 'to', 'say', '``', 'let', \"'s\", 'get', 'out', 'of', 'here', \"''\", 'at', 'least', 'three', 'times', 'during', 'the', 'movie', ',', 'twice', 'in', 'one', 'scene', '.', 'loads', 'of', 'things', 'are', 'left', 'unexplained', 'at', 'the', 'end', '-', 'why', 'do', 'the', 'aliens', 'need', 'all', 'the', 'heat', 'and', 'water', 'for', 'example', '?', '-', 'not', 'that', 'anyone', 'watching', 'would', 'care', ';', 'if', 'the', 'film', 'makers', 'did', \"n't\", 'care', 'why', 'should', 'we', '?', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'acting', 'is', 'adequate', '-', 'better', 'than', 'the', 'script', ',', 'which', 'at', 'times', ',', 'has', 'an', '<UNK>', '<UNK>', 'quality', ',', 'deserves', '.', 'though', 'often', 'the', 'actors', 'look', 'like', 'they', 'just', 'want', 'to', 'get', 'the', 'thing', 'over', 'with', 'as', 'quickly', 'as', 'possible', '-', 'a', 'notable', 'example', 'of', 'this', 'is', 'when', 'elizabeth', '<UNK>', '<UNK>', 'the', '<UNK>', ',', 'token', 'moment', 'of', '``', 'frustrated', 'despair', 'hands', 'to', 'face', '<UNK>', \"''\", 'before', 'following', '<UNK>', 'son', '<UNK>', 'outside', 'to', 'watch', 'him', 'do', '``', 'angry', '<UNK>', 'teenager', 'smashing', 'something', 'off', 'a', 'table', \"''\", '<UNK>', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'continuity', 'errors', 'include', 'the', '(', '<UNK>', ')', '<UNK>', 'on', 'the', 'back', 'of', '<UNK>', \"'s\", 'jeep', 'appearing', 'and', 'disappearing', ',', 'a', 'double', 'action', 'of', 'the', 'gas', 'in', 'the', 'exploding', 'car', ',', 'a', '<UNK>', 'being', 'in', 'two', 'places', 'simultaneously', '-', 'once', 'in', 'the', 'alien', '<UNK>', \"'s\", '<UNK>', 'shot', 'then', 'immediately', 'afterwards', 'in', 'a', 'reaction', 'shot', ',', 'elizabeth', '<UNK>', 'appearing', 'to', 'shut', 'a', 'car', 'door', 'twice', '...', 'you', 'can', 'tell', 'i', 'was', '<UNK>', 'ca', \"n't\", 'you', '?', 'the', 'movie', 'commits', 'that', 'greatest', 'of', 'errors', '.', 'it', \"'s\", 'boring', '.']\n",
      "Modified review <UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>\n",
      "True review ['i', 'agree', 'with', 'the', 'comments', 'regarding', 'the', '<UNK>', 'spin', '.', 'the', 'last', 'view', 'shows', 'have', 'been', 'a', 'little', 'better', ',', 'but', 'surely', 'the', 'writers', 'need', 'some', 'more', 'direction', '.', 'i', 'think', 'the', 'characters', 'are', 'still', 'interesting', ',', 'although', 'sometimes', 'they', 'spin', 'into', 'the', '``', 'white', 'trash', \"''\", 'things', 'a', 'little', 'too', 'much', '.', 'subtlety', 'and', '<UNK>', 'goes', 'a', 'long', 'way', 'on', 'shows', 'like', '``', 'office', \"''\", '.', 'i', 'would', 'think', 'the', 'target', 'audience', 'is', 'somewhat', 'similar', 'being', 'they', 'are', 'both', 'on', 'the', 'same', 'night', 'and', '<UNK>', '.', 'one', 'would', 'think', 'that', '<UNK>', 'and', 'the', 'whole', 'eastern', 'religion', 'thing', 'is', 'a', 'big', 'enough', 'topic', 'to', 'bring', 'some', 'different', 'and', 'interesting', 'shows', ',', 'but', 'they', 'only', 'scratch', 'the', 'surface', 'of', 'the', 'subject', '.', 'in', 'my', 'opinion', 'it', 'shows', 'the', 'contempt', 'that', 'many', 'people', 'have', 'in', 'hollywood', 'about', 'the', 'level', 'of', 'intelligence', 'of', 'the', 'masses', '.', 'we', 'can', 'handle', 'more', '<UNK>', 'content', '.', 'it', 'has', 'been', 'proved', 'before', 'in', 'many', 'other', 'shows', '.']\n",
      "Modified review <UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>\n",
      "True review ['i', 'picked', 'up', 'this', 'movie', 'with', 'the', 'intention', 'of', 'getting', 'a', 'bad', 'zombie', 'movie', '.', 'but', 'i', 'had', 'no', 'idea', 'what', 'i', 'was', 'getting', 'myself', '<UNK>', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'started', 'the', 'movie', 'and', 'soon', 'i', 'had', 'been', 'pulled', 'into', 'a', 'world', 'of', 'pain', 'and', 'visual', '<UNK>', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'finally', 'know', 'what', 'hell', 'is', 'like', '.', 'it', \"'s\", 'this', 'movie', '.', 'for', 'eternity', '.', 'this', 'movie', 'has', 'no', 'value', '.', 'it', 'did', \"n't\", 'even', 'really', 'have', 'a', 'plot', '.', 'there', 'was', 'stuff', 'going', 'on', 'in', 'each', 'scene', 'but', 'no', 'overall', 'explanation', 'why', 'anything', '<UNK>', '<', 'br', '/', '>', '<', 'br', '/', '>', 'instead', 'of', 'watching', 'this', 'movie', 'i', 'suggest', 'that', 'you', 'line', 'the', 'nearest', '<UNK>', 'with', 'oil', 'and', 'try', 'and', 'stuff', 'as', 'many', 'bullets', 'in', 'it', 'as', 'you', 'can', '.', 'you', 'will', 'find', 'that', 'the', 'outcome', 'to', 'be', 'far', 'more', 'pleasant', 'than', 'this', 'movie.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'do', \"n't\", 'even', 'watch', 'it', '.', 'not', 'even', 'to', 'see', 'how', 'bad', 'it', 'is', '.', 'i', 'beg', 'you', '.', 'if', 'you', 'watch', 'it', ',', 'then', 'it', 'means', 'they', 'win', '.']\n",
      "Modified review <UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>.<UNK>\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "C = 3\n",
    "for (i,a ,b) in test_loader :\n",
    "    while k < C:\n",
    "        y = b[k].view(1)\n",
    "        x = a[k].view(1,seq_len,input_size)\n",
    "        recons = intervention(cc_vae, x, y)\n",
    "        dec = decode_recons(recons)\n",
    "        print(\"True review\", df_tok.iloc[i[k].item()]['review'])\n",
    "        print(\"Modified review\", dec)\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, z_dim, hidden_dim, num_classes, bidirectional=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_factor = 2 if bidirectional else 1\n",
    "        \n",
    "        self.encoder = nn.LSTM(input_size, hidden_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.locs = nn.Linear(hidden_dim*self.hidden_factor, z_dim)\n",
    "        self.scales = nn.Linear(hidden_dim*self.hidden_factor, z_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # x should be of shape [batch_size, seq_len, input_size]\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0).unsqueeze(0)  # shape [1, 1, input_size]\n",
    "        elif x.dim() == 2:\n",
    "            x = x.unsqueeze(2)  # shape [batch_size, 1, input_size]\n",
    "\n",
    "        y = y.view(batch_size,self.num_classes,self.input_size)\n",
    "        x_cat_y = torch.cat((x,y), 1)\n",
    "\n",
    "        output, (hidden, c_n) = self.encoder(x_cat_y)\n",
    "       \n",
    "        hidden = hidden.view(batch_size, self.hidden_dim*self.hidden_factor)\n",
    "\n",
    "        locs = self.locs(hidden)\n",
    "        scales = torch.clamp(F.softplus(self.scales(hidden)), min=1e-3)\n",
    "        return locs, scales\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, z_dim, num_classes, hidden_dim, vocab_size, seq_len,bidirectional=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.input_size = input_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_factor = 2 if bidirectional else 1\n",
    "\n",
    "        # Linear layer to transform z_dim to hidden_dim\n",
    "        self.linear = nn.Linear(z_dim + num_classes, hidden_dim * self.hidden_factor)\n",
    "\n",
    "        # LSTM to generate sequences\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.output = nn.Linear(hidden_dim * self.hidden_factor, self.vocab_size + 1)\n",
    "        \n",
    "    def forward(self, z, ysoft, xs):\n",
    "        batch_size = z.size(0)\n",
    "        z_cat_ysoft = torch.cat((z,ysoft), dim=1)\n",
    "        hidden = self.linear(z_cat_ysoft).view(self.hidden_factor, batch_size, self.hidden_dim)\n",
    "\n",
    "        #if self.bidirectional or self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            #hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_dim)\n",
    "        \n",
    "        if xs.is_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        c_0 = torch.zeros(self.hidden_factor, batch_size, self.hidden_dim)  # Shape: [hidden_factor, batch_size, hidden_dim]\n",
    "        if xs.is_cuda:\n",
    "            c_0 = c_0.cuda()\n",
    "        \n",
    "        decoder_hidden = (hidden, c_0)\n",
    "        outputs, _ = self.lstm(xs, decoder_hidden)\n",
    "\n",
    "        outputs = self.output(outputs)\n",
    "\n",
    "        logp = nn.functional.log_softmax(outputs, dim=-1)\n",
    "\n",
    "        return logp\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim,num_classes)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        # x should be of shape [batch_size, seq_len, input_size]\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(0).unsqueeze(0)  # shape [1, 1, input_size]\n",
    "        elif x.dim() == 2:\n",
    "            x = x.unsqueeze(2)  # shape [batch_size, 1, input_size]\n",
    "            \n",
    "        _, (h,c) = self.lstm(x)\n",
    "        logits = self.linear(h[-1])\n",
    "        #preds = self.softmax(logits)\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return logits, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_log_likelihood(recon, xs):\n",
    "    vocab_size = recon.shape[-1] \n",
    "    \n",
    "    target = xs.squeeze(-1)  # Shape: (batch_size, seq_len)\n",
    "    target = target.long()\n",
    "\n",
    "    # Reshape output and target for CrossEntropyLoss\n",
    "    recon = recon.view(-1, vocab_size)  # Shape: (batch_size * seq_len, vocab_size)\n",
    "    target = target.view(-1)  # Shape: (batch_size * seq_len)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(recon, target)\n",
    "    return loss\n",
    "\n",
    "class m2_model(nn.Module):\n",
    "    def __init__(self,input_size, z_dim, num_classes, hidden_dim, seq_len, vocab_size, batch_size,use_cuda):\n",
    "        super(m2_model, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.input_size = input_size\n",
    "        self.z_dim = z_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = Encoder(self.input_size, self.z_dim, self.hidden_dim, num_classes)\n",
    "        self.decoder = Decoder(self.input_size, self.z_dim, self.num_classes, self.hidden_dim, self.vocab_size, self.seq_len)\n",
    "        self.classifier = Classifier(self.input_size, self.hidden_dim, self.num_classes)\n",
    "\n",
    "        self.cat_loss = nn.BCEWithLogitsLoss(reduce=False)\n",
    "    \n",
    "    def sup(self, x, y):\n",
    "        logits, preds = self.classifier(x)\n",
    "        locs_z, scales_z = self.encoder(x,y)\n",
    "        z = dist.Normal(locs_z, scales_z).rsample()\n",
    "        recons = self.decoder(z,preds,x)\n",
    "        \n",
    "        llk = sentence_log_likelihood(recons,x)\n",
    "        \n",
    "        cat = self.cat_loss(logits.squeeze(1),y.float())\n",
    "        kld_norm = torch.sum(0.5 * ( locs_z**2 + scales_z - 1 - torch.log(scales_z)),-1)\n",
    "        \n",
    "        loss = (llk + cat + kld_norm).mean()\n",
    "\n",
    "        return loss, llk, cat, kld_norm\n",
    "    \n",
    "    def classifier_acc(self, x, y=None, k=1):\n",
    "        _, preds = self.classifier(x)\n",
    "        preds = torch.round(preds)\n",
    "        acc = (preds.eq(y)).float().mean()\n",
    "        return acc\n",
    "    \n",
    "    def accuracy(self, data_loader, *args, **kwargs):\n",
    "        acc = 0.0\n",
    "        for (_, x, y) in data_loader:\n",
    "            if self.use_cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            batch_acc = self.classifier_acc(x, y)\n",
    "            acc += batch_acc\n",
    "        return acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\Documents\\.venv\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "  Batch: 0\n",
      "Batch 0 Loss: 15.509\n",
      "Gradient norm: 69.520\n",
      "  Batch: 1\n",
      "Batch 1 Loss: 13.226\n",
      "Gradient norm: 141.523\n",
      "  Batch: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#print(\"llk\", llk.shape, llk.mean())\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#print(\"cat\", cat.shape, cat.mean())\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#print(\"kld_norm\", kld_norm.shape, kld_norm.mean())\u001b[39;00m\n\u001b[0;32m     27\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     31\u001b[0m epoch_losses_sup \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Arthur\\Documents\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arthur\\Documents\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arthur\\Documents\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Training\n",
    "m2 = m2_model(input_size, z_dim, num_classes, hidden_dim, seq_len, vocab_size, batch_size, use_cuda)\n",
    "\n",
    "m2.apply(init_weights)\n",
    "\n",
    "optim = torch.optim.Adam(params=m2.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    m2.train()\n",
    "    \n",
    "    epoch_losses_sup = 0.0\n",
    "    #for i in tqdm(range(num_batch)):\n",
    "    for batch_idx, (_, xs, ys) in enumerate(train_loader):\n",
    "        print(\"  Batch:\", batch_idx)\n",
    "        #xs, ys = next(train_loader)\n",
    "        xs = xs.view(batch_size, seq_len, input_size)\n",
    "        loss, llk, cat, kld_norm = m2.sup(xs, ys)\n",
    "\n",
    "        #print(\"llk\", llk.shape, llk.mean())\n",
    "        #print(\"cat\", cat.shape, cat.mean())\n",
    "        #print(\"kld_norm\", kld_norm.shape, kld_norm.mean())\n",
    "\n",
    "\n",
    "        optim.zero_grad() \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_losses_sup += loss.detach().item()\n",
    "        print(f\"Batch {batch_idx} Loss: {loss.detach().item():.3f}\")\n",
    "\n",
    "        # Debugging: Print gradient norms\n",
    "        total_norm = 0\n",
    "        for p in m2.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "        print(f\"Gradient norm: {total_norm:.3f}\")\n",
    "\n",
    "        gc.collect()\n",
    "    \n",
    "    avg_loss = epoch_losses_sup / len(train_loader)\n",
    "    print(f\"[Epoch {epoch+1:03d}] Sup Loss: {avg_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4939)\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "m2.eval() \n",
    "\n",
    "test_acc = m2.accuracy(test_loader)\n",
    "\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
